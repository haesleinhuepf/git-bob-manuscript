%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Manuscript file by Robert Haase, license CC-BY 4.0
%%%
%%% https://github.com/haesleinhuepf/git-bob-manuscript
%%% https://creativecommons.org/licenses/by/4.0/deed.en 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% LaTeX Template for ECAI Papers 
%%% Prepared by Ulle Endriss (version 1.0 of 2023-12-10)

%%% To be used with the ECAI class file ecai.cls.
%%% You also will need a bibliography file (such as mybibfile.bib).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Start your document with the \documentclass{} command.
%%% Use the first variant for the camera-ready paper.
%%% Use the second variant for submission (for double-blind reviewing).

\documentclass{ecai} 
%\documentclass[doubleblind]{ecai} 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Load any packages you require here. 

\usepackage{latexsym}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{color}
\usepackage{hyperref}

\usepackage{adjustbox}
\usepackage{array}
\usepackage{booktabs}
\usepackage{multirow}

\newcolumntype{R}[2]{%
    >{\adjustbox{angle=#1,lap=\width-(#2)}\bgroup}%
    l%
    <{\egroup}%
}
\newcommand*\rot{\multicolumn{1}{R{90}{1em}}}% no optional argument here, please!


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Define any theorem-like environments you require here.

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{definition}{Definition}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Define any new commands you require here.

\newcommand{\BibTeX}{B\kern-.05em{\sc i\kern-.025em b}\kern-.08em\TeX}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frontmatter}

%%% Use this command to specify your submission number.
%%% In doubleblind mode, it will be printed on the first page.

\paperid{363} 

%%% Use this command to specify the title of your paper.

\title{Towards Reproducibility and Knowledge Transfer in AI-assisted Data Analysis Code Generation}

%%% Use this combinations of commands to specify all authors of your 
%%% paper. Use \fnms{} and \snm{} to indicate everyone's first names 
%%% and surname. This will help the publisher with indexing the 
%%% proceedings. Please use a reasonable approximation in case your 
%%% name does not neatly split into "first names" and "surname".
%%% Specifying your ORCID digital identifier is optional. 
%%% Use the \thanks{} command to indicate one or more corresponding 
%%% authors and their email address(es). If so desired, you can specify
%%% author contributions using the \footnote{} command.

\author[A,B]{\fnms{Robert}~\snm{Haase}\orcid{0000-0001-5949-2327}\thanks{Corresponding Author. Email: robert.haase@uni-leipzig.de}}

\address[A]{Data Science Center, Leipzig University, Humboldtstra{\ss}e 25, 04105 Leipzig, Germany}
\address[B]{Center for Scalable Data Analytics and Artificial Intelligence (ScaDS.AI) Dresden / Leipzig}

%%% Use this environment to include an abstract of your paper.

\begin{abstract}

Abstract will be added later

\end{abstract}

\end{frontmatter}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

Generative artificial intelligence and Large-language models (LLMs) in particular are changing the way we do data science. Most prominently, scientists use the technology for generating data analysis code \citep{Royer2023, royer2023omega} and [re-]writing text. Prompts are commonly not stored so that knowledge transfer between scientists on how to prompt efficiently and responsibly is hindered. At the time of publication of scientific code and manuscripts, it may be hard to reproduce the scientific workflow that lead to a given set of data analysis code and to identify the parts of the project which were implemented by the human and the parts that were created by an LLM. A professional peer-review system documenting which human read and confirmed LLM-written code is not established in contemporary scientific culture. Such systems do exist for collaborative code editing involving multiple humans. E.g. the github.com online platform is well-established in the open-source community for discussing issues, for sharing potential solutions, and for reviewing code. It was also shown before that LLMs can solve real-world GitHub issues \citep{jimenez2024swebenchlanguagemodelsresolve}. I am presenting git-bob, a practical implementation of an LLM-based assistant that can answer to GitHub issues, discuss potential solutions with humans iteratively, write code for them, and submit it as pull-request to reviewed by humans. With such a tool, interaction between humans and LLMs can be documented and later reproduced why data analysis is written in a certain way, if it was written by a human or an LLM, and if it was generated by an LLM, which human reviewed the code before it became part of the entire solution. In a world where scientists demonstrate that LLM-based systems can write entire papers, review and improve them \citep{lu2024aiscientist} independently, such a solution is urgently need to be established as part of good scientific practice. git-bob is available open-source: \url{https://github.com/haesleinhuepf/git-bob}

\begin{figure*}[h]
\centering
\includegraphics[width=0.82\textwidth]{fig1_example_interaction.png}
\caption{example interaction with git-bob - figure placeholder
\newline
\newline
}
\label{fig:exampleinteraction}
\end{figure*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

A common workflow, demonstrated in Figure \ref{fig:exampleinteraction}A, is that a user opens an issue on a repository on Github.com, where git-bob is installed. If the user is repository member, they can trigger git-bob to answer. If they are externals, a repository member has to do this. git-bob may then answer the question, potentially including a code snippet. Multiple users and the AI-assistant can then argue back and forth until some potential solution is reached. Git-bob can then formulate a GitHub pull-request, e.g. with a Jupyter Notebook containing the entire solution to a given issue. A human needs to review this pull-request and merge it into the code base of the repository. Git-bob also has the capability to review pull-requests, e.g. originating from humans, but it is not allowed to merge them. This reflects established practices in science, where eventually a human is reponsible for data anaylsis code that becomes part of the project.

A highlight of the implementation is that no local installation or institutional internet server is required. Git-bob is implemented as GitHub Workflow, and hence runs within the IT infrastructure of github.com. It is compatible with OpenAI's LLMs such as GPT4, Anthropic's Claude, Google Gemini, and models hosted on Github Models Marketplace. The first three of these vendors require payment for using their services through an application programming interface (API), the fourth offers usage of their API for free. Obviously, the communication with the selected LLM is transmitted to the service provider, including source code files from the repository and images provided with the github issue. Hence, users are recommended to not submit any personal or sensitive information. Git-bob reports which model was used in all of its messages, as good scientific practice may suggest.

No new graphical interface needs to be learned, as git-bob integrates well with pre-existing workflows, formerly only between humans, now facilitating interaction with LLMs. Users also do not need to copy and paste code fragments between chat windows and code editors. Furthermore, it allows interaction of multiple humans with the LLM within the same context. E.g. an open source software user can reach out with a question about how to analyse an image, a bio-image analysis expert can point out a potential  strategy and the LLM implements the details, which can then be reviewed by the user and the expert. With this, multi-turn interaction with the LLM is enabled using direct text input and additional files from a given repository. When used with a vision language model (VLM) such as OpenAI's GPT4-omni, that can take an image as optional input, it can describe image content and with this, may have a better informed starting point for designing a bio-image analysis workflow.
Git-bob can be configured for different purposes, such as assisting in code writing, data analysis, manuscript writing, code reviewing, and as outlined above for answering questions of externals reaching out to developers of open source repositories. This configuration is done by modifying system messages in the Github Workflow configuration file. 

Git-bob can be used in private repositories giving scientists the necessary privacy to work on code and documentation before they eventually publish their work. For example, this manuscript was edited with LLM-assistance in a private repository, and the reader can finally see which modifications were done by the human, and how the AI-assistant contributed to the work as shown in in Figure \ref{fig:exampleinteraction}C.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion}

LLMs are being integrated in contemporary scientific workflows unavoidably, but documentation of how in detail they are imployed is commonly not done, also because of lack of tools doing this conveniently. To use LLMs responsibly, documenting how they were used in a specific project seems good-scientific-practice. If the scientific community documented usage of LLM prompts like they document usage of open source data analysis libraries, we could learn from each other how to prompt efficiently and responsibly. Git-bob allows facilitating this on multiple levels: for code generation, but also for manuscript writing. It works integrated on github.com enabling scientists to interact with an LLM via Github Issues and Pull-Requests offering new ways for establishing good scientific practice for the interaction between humans and artificial intelligence when working on projects together.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Use this environment to include acknowledgements (optional).
%%% This will be omitted in doubleblind mode.

\begin{ack}
RH acknowledges the financial support by the Federal Ministry of Education and Research of Germany and by Sächsische Staatsministerium für Wissenschaft, Kultur und Tourismus in the programme Center of Excellence for AI-research "Center for Scalable Data Analytics and Artificial Intelligence Dresden/Leipzig", project identification number: ScaDS.AI.

\end{ack}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%% Use this command to include your bibliography file.

\bibliography{mybibfile}

\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
